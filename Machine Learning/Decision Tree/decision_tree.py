# -*- coding: utf-8 -*-
"""Decision Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qhct3z1-NtVxJwgUc8UKuoPuM31gyzk4
"""

import math
from sklearn import datasets
import numpy as np

def entropy(p1,n1):
  if p1==0 and n1==0:
    return 1
  elif p1==0 or n1==0:
    return 0
  else:
    return -(p1/(p1+n1))*math.log2(p1/(p1+n1))-(n1/(p1+n1))*math.log2(n1/(p1+n1))

def IG(p1,n1,p2,n2):
  num = p1+n1+p2+n2
  num1 = p1+n1
  num2 = p2+n2
  return entropy(p1+p2,n1+n2)-(num1/num*entropy(p1,n1)+num2/num*entropy(p2,n2))
#print(IG(21,5,8,30))
#print(IG(18,33,11,2))

data = datasets.load_iris()
feature1 = data.data[50:80][:]
feature2 = data.data[100:130][:]
train_feature = np.concatenate((feature1,feature2),axis=0)
train_target = np.concatenate((data.target[50:80],data.target[100:130]))
train_target -= 1
feature1 = data.data[80:100][:]
feature2 = data.data[130:150][:]
test_feature = np.concatenate((feature1,feature2),axis=0)
test_target = np.concatenate((data.target[80:100],data.target[130:150]))
test_target -= 1

def ID3DTtrain(feature,target):
  node = dict()
  node['data'] = range(len(target))
  tree = []
  tree.append(node)
  t = 0
  while t<len(tree):
    idx = tree[t]['data']
    if sum(target[idx])==0:
      tree[t]['leaf'] = 1
      tree[t]['decision'] = 0
    elif sum(target[idx])==len(idx):
      tree[t]['leaf'] = 1
      tree[t]['decision'] = 1
    else:
      bestIG = 0
      for i in range(feature.shape[1]):
        pool = list(set(feature[idx,i]))
        pool.sort()
        for j in range(len(pool)-1):
          thres = (pool[j]+pool[j+1])/2
          G1 = []
          G2 = []
          for k in idx:
            if feature[k,i]<thres:
              G1.append(k)
            else:
              G2.append(k)
          p1 = sum(target[G1]==1)
          n1 = sum(target[G1]==0)
          p2 = sum(target[G2]==1)
          n2 = sum(target[G2]==0)
          thisIG = IG(p1,n1,p2,n2)
          if thisIG>bestIG:
            bestIG = thisIG
            bestG1 = G1
            bestG2 = G2
            bestthres = thres
            bestf = i
      if bestIG > 0:
        tree[t]['leaf'] = 0
        tree[t]['selectf'] = bestf
        tree[t]['threshold'] = bestthres
        tree[t]['child'] = [len(tree),len(tree)+1]
        node = dict()
        node['data'] = bestG1
        tree.append(node)
        node = dict()
        node['data'] = bestG2
        tree.append(node)
      else:
        tree[t]['leaf'] = 1
        tree[t]['decision'] = 1 if sum(target[idx])>len(idx)/2 else 0
    t+=1
  return tree
tree = ID3DTtrain(train_feature,train_target)
print(tree)

def ID3DTtest(feature,tree):
  [n,f]=feature.shape
  out = np.zeros((n,),dtype=int)
  for i in range(n):
    featurea = feature[i,:]
    t = 0
    while(tree[t]['leaf']==0):
      bestf = tree[t]['selectf']
      bestthres = tree[t]['threshold']
      if featurea[bestf]<bestthres:
        t = tree[t]['child'][0]
      else:
        t = tree[t]['child'][1]
    out[i] = tree[t]['decision']
  return out

train_prediction = ID3DTtest(train_feature,tree)
print(train_target)
print(train_prediction)
test_prediction = ID3DTtest(test_feature,tree)
print(test_target)
print(test_prediction)

TP = np.sum((test_target == 1) & (test_prediction == 1))
FP = np.sum((test_target == 0) & (test_prediction == 1))
FN = np.sum((test_target == 1) & (test_prediction == 0))
TN = np.sum((test_target == 0) & (test_prediction == 0))
Total = TP + FP + FN + TN


ACC = (TP + TN) / Total
TPR = TP / (TP + FN) if (TP + FN) > 0 else 0
FPR = FP / (FP + TN) if (FP + TN) > 0 else 0
PPV = TP / (TP + FP) if (TP + FP) > 0 else 0
NPV = TN / (TN + FN) if (TN + FN) > 0 else 0
F1_Score = 2 * (PPV * TPR) / (PPV + TPR) if (PPV + TPR) > 0 else 0


print(f"1. TPR : {TPR:.10f} ({TPR*100:.10f}%)")
print(f"2. FPR : {FPR:.10f} ({FPR*100:.10f}%)")
print(f"3. ACC : {ACC:.10f} ({ACC*100:.10f}%)")
print(f"4. PPV : {PPV:.10f} ({PPV*100:.10f}%)")
print(f"5. NPV : {NPV:.10f} ({NPV*100:.10f}%)")
print(f"6. F1-Score : {F1_Score:.10f}")