# -*- coding: utf-8 -*-
"""Neural Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1THdQ0UbgUBZPQfM-V7WnrF6MREpYAHkQ
"""

import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()

print(x_train.shape,y_train.shape,x_test.shape)
indices = range(1000,2000,100)
plt.imshow(tf.concat([x_train[i] for i in indices], axis=1), cmap='gray')
plt.axis('off')
plt.show()
print([int(y_train[i]) for i in indices])
x_train, x_test = x_train / 255.0, x_test / 255.0

overfitting_model =models.Sequential([
    layers.Flatten(input_shape=(28,28)),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(512,activation='relu'),
    layers.Dense(10,activation='softmax'),
])
overfitting_model.summary()
overfitting_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history = overfitting_model.fit(x_train,y_train,epochs=30,validation_split=0.1,batch_size=32)

val_loss_data = history.history['val_loss']
window_size = 5
smoothed_val_loss = pd.Series(val_loss_data).rolling( window=window_size , min_periods=1 ).mean()
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.plot(smoothed_val_loss, color='green',linestyle='dashed')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Overfitting_model')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Overfitting_model')
plt.legend()
plt.show()

test_loss, test_acc = overfitting_model.evaluate(x_test, y_test, verbose=0)
print('Overfitting_model:')
print(f'test_acc: {test_acc}')
print(f'test_loss: {test_loss}')

model_CNN = models.Sequential([
    layers.Conv2D(64,5,activation='relu',input_shape=(28,28,1)),
    layers.MaxPooling2D(),
    layers.Conv2D(20,5,activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(64,activation='relu'),
    layers.Dense(10,activation='softmax')
])
model_CNN.summary()
model_CNN.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])


model_deep = models.Sequential([
    layers.Flatten(input_shape=(28,28)),
    layers.Dense(64,activation='relu'),
    layers.Dense(32,activation='relu'),
    layers.Dense(32,activation='relu'),
    layers.Dense(16,activation='relu'),
    layers.Dense(16,activation='relu'),
    layers.Dense(16,activation='relu'),
    layers.Dense(16,activation='relu'),
    layers.Dense(8,activation='relu'),
    layers.Dense(8,activation='relu'),
    layers.Dense(8,activation='relu'),
    layers.Dense(8,activation='relu'),
    layers.Dense(10,activation='softmax'),
])
model_deep.summary()
model_deep.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])


model_shallow = models.Sequential([
    layers.Flatten(input_shape=(28,28)),
    layers.Dense(64,activation='relu'),
    layers.Dense(64,activation='relu'),
    layers.Dense(10,activation='softmax'),
])
model_shallow.summary()
model_shallow.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

CNN_history = model_CNN.fit(x_train,y_train,epochs=20,validation_split=0.1,batch_size=128)

Deep_history = model_deep.fit(x_train,y_train,epochs=20,validation_split=0.1,batch_size=128)

Shallow_history = model_shallow.fit(x_train,y_train,epochs=20,validation_split=0.1,batch_size=128)

plt.plot(CNN_history.history['accuracy'], label='train_acc')
plt.plot(CNN_history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('CNN_model')
plt.legend()
plt.show()

plt.plot(Deep_history.history['accuracy'], label='train_acc')
plt.plot(Deep_history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Deep fully-connection_model')
plt.legend()
plt.show()

plt.plot(Shallow_history.history['accuracy'], label='train_acc')
plt.plot(Shallow_history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Shallow fully-connection_model')
plt.legend()
plt.show()

plt.plot(CNN_history.history['accuracy'], label='CNN_train_acc')

plt.plot(Deep_history.history['accuracy'], label='Deep_train_acc')

plt.plot(Shallow_history.history['accuracy'], label='Shallow_train_acc')

plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Comparison')
plt.legend()
plt.show()

plt.plot(CNN_history.history['val_accuracy'], label='CNN_val_acc')

plt.plot(Deep_history.history['val_accuracy'], label='Deep_val_acc')

plt.plot(Shallow_history.history['val_accuracy'], label='Shallow_val_acc')

plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Comparison')
plt.legend()
plt.show()

test_loss, test_acc = model_CNN.evaluate(x_test, y_test, verbose=0)
print('CNN_model')
print()
print('Accuracy',test_acc)
print('Loss',test_loss)
print('-------------------------')

test_loss, test_acc = model_deep.evaluate(x_test, y_test, verbose=0)
print('Deep fully-connection model')
print()
print('Accuracy',test_acc)
print('Loss',test_loss)
print("-------------------------")

test_loss, test_acc = model_shallow.evaluate(x_test, y_test, verbose=0)
print('Shallow fully-connection model')
print()
print('Accuracy',test_acc)
print('Loss',test_loss)